apiVersion: v1
kind: ConfigMap
metadata:
  name: tempo-query
data:
  tempo-query.yaml: |
    backend: localhost:3100

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: tempo
data:
  overrides.yaml: |
    overrides:
  tempo.yaml: |
    auth_enabled: false

    compactor:
      compaction:
        # duration to keep blocks
        # block_retention: 336h # 14d
        block_retention: 1h
        # duration to keep blocks that have been compacted elsewhere
        # compacted_block_retention: 24h
        compacted_block_retention: 10m
        # blocks in this time window will be compacted together
        compaction_window: 1h
        # amount of data to buffer from input blocks
        # chunk_size_bytes: 10485760
        # flush data to backend when buffer is this large
        # flush_size_bytes: 31457280
        # maximum traces in a compacted block
        max_compaction_objects: 1000000
    
    distributor:
      # this configuration will listen on all ports and protocols that tempo is capable of.
      receivers:
        # the receives all come from the OpenTelemetry collector.  more configuration information can
        jaeger:
          # be found there: https://github.com/open-telemetry/opentelemetry-collector/tree/master/receiver
          protocols:
            thrift_http:
            # for a production deployment you should only enable the receivers you need!
            grpc:
            thrift_binary:
            thrift_compact:
        zipkin:
        otlp:
          protocols:
            http:
            grpc:
        opencensus:
    
    ingester:
      # amount of time before considering a trace complete and flushing it to a block
      trace_idle_period: 20s
      # maximum number of traces in a block before cutting it
      traces_per_block: 1000
      # this much time passes
      max_block_duration: 5m
    
    server:
      http_listen_port: 3100
    
    storage:
      trace:
        # backend configuration to use
        backend: local
        local:
          path: /var/tempo/traces
        # the worker pool is used primarily when finding traces by id, but is also used by other
        pool:
          # total number of workers pulling jobs from the queue
          # max_workers: 100
          max_workers: 50
          # length of job queue
          # queue_depth: 10000
          queue_depth: 2000
        wal:
          path: /var/tempo/wal
          # bloom filter false positive rate
          # lower values create larger filters but fewer false positives
          bloom_filter_false_positive: .05
          # number of traces per index record
          index_downsample: 10
